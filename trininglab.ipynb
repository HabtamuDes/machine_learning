{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image rotation\n",
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('face_1.jpg')\n",
    "\n",
    "cv2.imshow('Original Image', img) \n",
    "\n",
    "height, width = img.shape[0:2]\n",
    "\n",
    "cv2.getRotationMatrix2D(center, angle, scale)\n",
    "\n",
    "rotationMatrix = cv2.getRotationMatrix2D((width/2, height/2), 90, .5)\n",
    "\n",
    "rotatedImage = cv2.warpAffine(img, rotationMatrix, (width, height))\n",
    "\n",
    "cv2.imshow('Rotated Image', rotatedImage)\n",
    " \n",
    "\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"face_1.jpg\")\n",
    " \n",
    "height, width = img.shape[0:2]\n",
    "\n",
    "startRow = int(height*.15)\n",
    " \n",
    "startCol = int(width*.15)\n",
    " \n",
    "endRow = int(height*.85)\n",
    " \n",
    "endCol = int(width*.85)\n",
    "\n",
    "croppedImage = img[startRow:endRow, startCol:endCol]\n",
    "\n",
    "cv2.imshow('Original Image', img)\n",
    " \n",
    "cv2.imshow('Cropped Image', croppedImage)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllwindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling\n",
    "\n",
    "import cv2\n",
    " \n",
    "img = cv2.imread(\"face_1.jpg\")\n",
    "\n",
    "newImg = cv2.resize(img, (0,0), fx=0.75, fy=0.75)\n",
    " \n",
    "cv2.imshow('Resized Image', newImg)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "\n",
    "newImg = cv2.resize(img, (550, 350))\n",
    " \n",
    "cv2.imshow('Resized Image', newImg)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllwindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contrast \n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('face_1.jpg')\n",
    "\n",
    "contrast_img = cv2.addWeighted(img, 2.5, np.zeros(img.shape, img.dtype), 0, 0)\n",
    " \n",
    "cv2.imshow('Original Image', img)\n",
    " \n",
    "cv2.imshow('Contrast Image', contrast_img)\n",
    " \n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gussian bluring\n",
    "import cv2\n",
    " \n",
    "img = cv2.imread(\"face_1.jpg\")\n",
    " \n",
    "blur_image = cv2.GaussianBlur(img, (7,7), 0)\n",
    " \n",
    "cv2.imshow('Original Image', img)\n",
    " \n",
    "cv2.imshow('Blur Image', blur_image)\n",
    " \n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edge detection\n",
    "\n",
    "import cv2\n",
    "\n",
    " \n",
    "img = cv2.imread(\"face_1.jpg\")\n",
    " \n",
    "edge_img = cv2.Canny(img,100,200)\n",
    " \n",
    "cv2.imshow(\"Detected Edges\", edge_img)\n",
    " \n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting into gray scale\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"face_2.jpg\")\n",
    "\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow(\"Original Image\", img)\n",
    " \n",
    "cv2.imshow(\"Gray Scale Image\", gray_img)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllwindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "press b for brightness\n",
      "press d for darkness\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "what kind of operation do you want to perform on this image? b\n",
      "enter the brightness number? 67\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.1) /io/opencv/modules/core/src/arithm.cpp:663: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6808732fa0f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muser\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mbright\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"enter the brightness number?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mbrightness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"d\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-6808732fa0f4>\u001b[0m in \u001b[0;36mbrightness\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbrightness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mval\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mimg1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"normal_image\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.1.1) /io/opencv/modules/core/src/arithm.cpp:663: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "print(\"press b for brightness\")\n",
    "print(\"press d for darkness\")\n",
    "user = input(\"what kind of operation do you want to perform on this image?\" )\n",
    "\n",
    "\n",
    "img1=np.ones((512,512,3),np.uint8)\n",
    "img=cv2.imread(\"face_5.png\")\n",
    "\n",
    "\n",
    "\n",
    "def brightness(x):\n",
    "    val= img1 * x\n",
    "    mod = cv2.add(img,val)\n",
    "    cv2.imshow(\"normal_image\",img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.imshow(\"changed_image\",mod)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    \n",
    "def darkness(y):\n",
    "     v= img1 * y\n",
    "     d = cv2.subtract(img,v)\n",
    "     cv2.imshow(\"normal_image\",img)\n",
    "     cv2.waitKey(0)\n",
    "     cv2.imshow(\"changed_image\",d)\n",
    "     \n",
    "     cv2.waitKey(0)\n",
    "     \n",
    "\n",
    "\n",
    "if user == \"b\":\n",
    "    bright=int(input(\"enter the brightness number?\"))\n",
    "    brightness(bright)\n",
    "\n",
    "elif user==\"d\":\n",
    "    dark=int(input(\"enter the darkness number?\"))\n",
    "    darkness(dark)\n",
    "\n",
    "  \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
